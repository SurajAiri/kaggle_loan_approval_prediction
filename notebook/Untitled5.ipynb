{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoNQNL41d4CG",
        "outputId": "d762f1c9-a2ea-4450-de03-762c73e616c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ],
      "source": [
        "# !pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2eSgNdkZeMLO"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vO_0SQzHePfq"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "NUM_FOLD = 5\n",
        "\n",
        "train = pd.read_csv('../dataset/train.csv', index_col='id')\n",
        "test = pd.read_csv('../dataset/test.csv', index_col='id')\n",
        "original = pd.read_csv('../dataset/original.csv')\n",
        "sample_submission = pd.read_csv('../dataset/sample_submission.csv')\n",
        "\n",
        "\n",
        "\n",
        "cat_cols = list(test.select_dtypes(include=['object']).columns)\n",
        "\n",
        "for df in [train, test, original]:\n",
        "    for col in cat_cols:\n",
        "        df[col] = df[col].astype('str').astype('category')\n",
        "\n",
        "\n",
        "X = train.drop(['loan_status'], axis=1)\n",
        "y = train['loan_status']\n",
        "X_original = original.drop(['loan_status'], axis=1)\n",
        "y_original = original['loan_status']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iSTL7KixeSgy"
      },
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# # from lightgbm import LGBMClassifier\n",
        "# from catboost import CatBoostClassifier\n",
        "\n",
        "\n",
        "# # lgb_params = {\n",
        "# #     'objective': 'binary',\n",
        "# #     'metric': 'auc',\n",
        "# #     'random_state': 42,\n",
        "# #     'n_estimators': 1000,\n",
        "# #     'learning_rate': 0.05,\n",
        "# #     'max_depth': 6,\n",
        "# #     'num_leaves': 31,\n",
        "# #     'subsample': 0.8,\n",
        "# #     'colsample_bytree': 0.8,\n",
        "# # }\n",
        "# # cat_params = {\n",
        "# #     'loss_function': 'Logloss',\n",
        "# #     'eval_metric': 'AUC',\n",
        "# #     'random_seed': 42,\n",
        "# #     'iterations': 1000,\n",
        "# #     'learning_rate': 0.05,\n",
        "# #     'depth': 6,\n",
        "# #     'verbose': False,\n",
        "\n",
        "# # }\n",
        "\n",
        "\n",
        "# def objective(trials):\n",
        "#     loss_func = trials.suggest_categorical('loss_function', ['Logloss', 'CrossEntropy'])\n",
        "#     learning_rate = trials.suggest_uniform('learning_rate', 0.01, 0.1)\n",
        "#     depth = trials.suggest_int('depth', 4, 10)\n",
        "#     iterations = trials.suggest_int('iterations', 100, 1400)\n",
        "#     eval_metric = trials.suggest_categorical('eval_metric', ['AUC', 'Accuracy'])\n",
        "\n",
        "#     model = CatBoostClassifier(\n",
        "#         random_seed=42,\n",
        "#         loss_function=loss_func,\n",
        "#         learning_rate=learning_rate,\n",
        "#         depth=depth,\n",
        "#         iterations=iterations,\n",
        "#         eval_metric=eval_metric,\n",
        "#         verbose=False,\n",
        "#     )\n",
        "\n",
        "\n",
        "\n",
        "#     skf = StratifiedKFold(n_splits=NUM_FOLD, shuffle=True, random_state=42)\n",
        "#     scores = []\n",
        "#     for train_index, valid_index in skf.split(X, y):\n",
        "#         X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
        "#         y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
        "#         model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
        "#         y_pred = model.predict_proba(X_valid)[:, 1]\n",
        "#         score = roc_auc_score(y_valid, y_pred)\n",
        "#         scores.append(score)\n",
        "\n",
        "#     return np.mean(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MbSywQ3XnoHZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "\n",
        "# lgb_params = {\n",
        "#     'objective': 'binary',\n",
        "#     'metric': 'auc',\n",
        "#     'random_state': 42,\n",
        "#     'n_estimators': 1000,\n",
        "#     'learning_rate': 0.05,\n",
        "#     'max_depth': 6,\n",
        "#     'num_leaves': 31,\n",
        "#     'subsample': 0.8,\n",
        "#     'colsample_bytree': 0.8,\n",
        "# }\n",
        "# cat_params = {\n",
        "#     'loss_function': 'Logloss',\n",
        "#     'eval_metric': 'AUC',\n",
        "#     'random_seed': 42,\n",
        "#     'iterations': 1000,\n",
        "#     'learning_rate': 0.05,\n",
        "#     'depth': 6,\n",
        "#     'verbose': False,\n",
        "\n",
        "# }\n",
        "\n",
        "\n",
        "def objective(trials):\n",
        "    loss_func = trials.suggest_categorical('loss_function', ['Logloss', 'CrossEntropy'])\n",
        "    learning_rate = trials.suggest_uniform('learning_rate', 0.01, 0.1)\n",
        "    depth = trials.suggest_int('depth', 4, 10)\n",
        "    iterations = trials.suggest_int('iterations', 100, 1400)\n",
        "    eval_metric = trials.suggest_categorical('eval_metric', ['AUC', 'Accuracy'])\n",
        "\n",
        "    model = CatBoostClassifier(\n",
        "        random_seed=42,\n",
        "        loss_function=loss_func,\n",
        "        learning_rate=learning_rate,\n",
        "        depth=depth,\n",
        "        iterations=iterations,\n",
        "        eval_metric=eval_metric,\n",
        "        verbose=False,\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=NUM_FOLD, shuffle=True, random_state=42)\n",
        "    scores = []\n",
        "    for train_index, valid_index in skf.split(X, y):\n",
        "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
        "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
        "        # Explicitly specify categorical features for CatBoost\n",
        "        model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], cat_features=cat_cols)\n",
        "        y_pred = model.predict_proba(X_valid)[:, 1]\n",
        "        score = roc_auc_score(y_valid, y_pred)\n",
        "        scores.append(score)\n",
        "\n",
        "    return np.mean(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WClLfFhfjbG",
        "outputId": "49220a18-677d-42c5-994a-d463d1cf41ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2024-10-13 12:22:17,592] A new study created in memory with name: lgbm_loan\n",
            "[I 2024-10-13 12:23:28,403] Trial 0 finished with value: 0.9482638183221985 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.03743587139314545, 'depth': 9, 'iterations': 710, 'eval_metric': 'Accuracy'}. Best is trial 0 with value: 0.9482638183221985.\n",
            "[I 2024-10-13 12:24:13,245] Trial 1 finished with value: 0.956138721661955 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.08955224063660172, 'depth': 4, 'iterations': 854, 'eval_metric': 'AUC'}. Best is trial 1 with value: 0.956138721661955.\n",
            "[I 2024-10-13 12:25:25,327] Trial 2 finished with value: 0.9495743020371427 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.08508374161944439, 'depth': 10, 'iterations': 496, 'eval_metric': 'AUC'}. Best is trial 1 with value: 0.956138721661955.\n",
            "[I 2024-10-13 12:25:42,696] Trial 3 finished with value: 0.9382980058374155 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.03366633409564083, 'depth': 8, 'iterations': 202, 'eval_metric': 'Accuracy'}. Best is trial 1 with value: 0.956138721661955.\n",
            "[I 2024-10-13 12:26:02,323] Trial 4 finished with value: 0.9410675576970128 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.03486435392079196, 'depth': 8, 'iterations': 238, 'eval_metric': 'Accuracy'}. Best is trial 1 with value: 0.956138721661955.\n",
            "[I 2024-10-13 12:26:56,553] Trial 5 finished with value: 0.947487774227864 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.03462257517873974, 'depth': 4, 'iterations': 998, 'eval_metric': 'Accuracy'}. Best is trial 1 with value: 0.956138721661955.\n",
            "[I 2024-10-13 12:28:00,436] Trial 6 finished with value: 0.9468326811929378 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.01928012080510736, 'depth': 5, 'iterations': 1149, 'eval_metric': 'Accuracy'}. Best is trial 1 with value: 0.956138721661955.\n",
            "[I 2024-10-13 12:28:33,683] Trial 7 finished with value: 0.9538400443372128 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.06855956322961392, 'depth': 7, 'iterations': 489, 'eval_metric': 'AUC'}. Best is trial 1 with value: 0.956138721661955.\n",
            "[I 2024-10-13 12:28:55,492] Trial 8 finished with value: 0.9479674114342147 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.08373224423481206, 'depth': 9, 'iterations': 233, 'eval_metric': 'Accuracy'}. Best is trial 1 with value: 0.956138721661955.\n",
            "[I 2024-10-13 12:28:59,908] Trial 9 finished with value: 0.9066622079431952 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.010670696694049873, 'depth': 9, 'iterations': 133, 'eval_metric': 'Accuracy'}. Best is trial 1 with value: 0.956138721661955.\n",
            "[I 2024-10-13 12:30:24,305] Trial 10 finished with value: 0.9565355420980287 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.09946072552459954, 'depth': 6, 'iterations': 1291, 'eval_metric': 'AUC'}. Best is trial 10 with value: 0.9565355420980287.\n",
            "[I 2024-10-13 12:31:51,413] Trial 11 finished with value: 0.9564752868256925 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.0997957797893453, 'depth': 6, 'iterations': 1356, 'eval_metric': 'AUC'}. Best is trial 10 with value: 0.9565355420980287.\n",
            "[I 2024-10-13 12:33:20,364] Trial 12 finished with value: 0.9565224576198037 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.09659082635678055, 'depth': 6, 'iterations': 1382, 'eval_metric': 'AUC'}. Best is trial 10 with value: 0.9565355420980287.\n",
            "[I 2024-10-13 12:34:47,536] Trial 13 finished with value: 0.9568335205520959 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.06862021495076757, 'depth': 6, 'iterations': 1355, 'eval_metric': 'AUC'}. Best is trial 13 with value: 0.9568335205520959.\n",
            "[I 2024-10-13 12:36:03,583] Trial 14 finished with value: 0.9563898507786097 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.06301560852626446, 'depth': 6, 'iterations': 1173, 'eval_metric': 'AUC'}. Best is trial 13 with value: 0.9568335205520959.\n",
            "[I 2024-10-13 12:37:12,383] Trial 15 finished with value: 0.9570902215848648 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.07226226550953908, 'depth': 5, 'iterations': 1192, 'eval_metric': 'AUC'}. Best is trial 15 with value: 0.9570902215848648.\n",
            "[I 2024-10-13 12:38:12,275] Trial 16 finished with value: 0.956771908018142 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.07172224154708545, 'depth': 5, 'iterations': 1041, 'eval_metric': 'AUC'}. Best is trial 15 with value: 0.9570902215848648.\n",
            "[I 2024-10-13 12:39:21,368] Trial 17 finished with value: 0.9557790354275048 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.0489369036199178, 'depth': 5, 'iterations': 1208, 'eval_metric': 'AUC'}. Best is trial 15 with value: 0.9570902215848648.\n",
            "[I 2024-10-13 12:40:26,260] Trial 18 finished with value: 0.9548545140556941 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.05285628763175376, 'depth': 7, 'iterations': 903, 'eval_metric': 'AUC'}. Best is trial 15 with value: 0.9570902215848648.\n",
            "[I 2024-10-13 12:41:02,929] Trial 19 finished with value: 0.9545696081740486 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.07822638939533177, 'depth': 4, 'iterations': 713, 'eval_metric': 'AUC'}. Best is trial 15 with value: 0.9570902215848648.\n",
            "[I 2024-10-13 12:42:04,985] Trial 20 finished with value: 0.9562408853631835 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.058871662263465664, 'depth': 5, 'iterations': 1064, 'eval_metric': 'AUC'}. Best is trial 15 with value: 0.9570902215848648.\n",
            "[I 2024-10-13 12:43:07,424] Trial 21 finished with value: 0.9565591870241026 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.07229016344969741, 'depth': 5, 'iterations': 1069, 'eval_metric': 'AUC'}. Best is trial 15 with value: 0.9570902215848648.\n",
            "[I 2024-10-13 12:44:20,261] Trial 22 finished with value: 0.9569854624184378 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.07156171501240281, 'depth': 5, 'iterations': 1258, 'eval_metric': 'AUC'}. Best is trial 15 with value: 0.9570902215848648.\n",
            "[I 2024-10-13 12:45:51,055] Trial 23 finished with value: 0.9555246679322537 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.06373755956153372, 'depth': 7, 'iterations': 1265, 'eval_metric': 'AUC'}. Best is trial 15 with value: 0.9570902215848648.\n",
            "[I 2024-10-13 12:47:19,960] Trial 24 finished with value: 0.9562574582418819 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.04603726108369875, 'depth': 6, 'iterations': 1392, 'eval_metric': 'AUC'}. Best is trial 15 with value: 0.9570902215848648.\n",
            "[I 2024-10-13 12:48:26,665] Trial 25 finished with value: 0.9570639097587706 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.0784135681554207, 'depth': 4, 'iterations': 1267, 'eval_metric': 'AUC'}. Best is trial 15 with value: 0.9570902215848648.\n",
            "[I 2024-10-13 12:49:14,037] Trial 26 finished with value: 0.9554383032324854 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.07785136469501253, 'depth': 4, 'iterations': 907, 'eval_metric': 'AUC'}. Best is trial 15 with value: 0.9570902215848648.\n",
            "[I 2024-10-13 12:50:14,296] Trial 27 finished with value: 0.9568573202536175 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.07619754876045946, 'depth': 4, 'iterations': 1153, 'eval_metric': 'AUC'}. Best is trial 15 with value: 0.9570902215848648.\n",
            "[I 2024-10-13 12:51:27,359] Trial 28 finished with value: 0.9578240596052154 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.08881827847947872, 'depth': 5, 'iterations': 1243, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 12:51:58,612] Trial 29 finished with value: 0.9546356258553574 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.09237225233937156, 'depth': 4, 'iterations': 607, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 12:52:45,543] Trial 30 finished with value: 0.9564975983017563 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.08513776358192876, 'depth': 5, 'iterations': 813, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 12:53:58,918] Trial 31 finished with value: 0.9572118393692783 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.08109843773797931, 'depth': 5, 'iterations': 1265, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 12:55:05,899] Trial 32 finished with value: 0.957572037553286 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.09261735004349152, 'depth': 4, 'iterations': 1287, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 12:56:01,923] Trial 33 finished with value: 0.9568193050225229 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.09069370669224007, 'depth': 5, 'iterations': 965, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 12:56:59,480] Trial 34 finished with value: 0.9572516047535112 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.08558110442711653, 'depth': 4, 'iterations': 1110, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 12:57:56,691] Trial 35 finished with value: 0.9569286360175564 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.08462541466576173, 'depth': 4, 'iterations': 1103, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 12:59:05,429] Trial 36 finished with value: 0.9536753454022465 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.09249540990868865, 'depth': 4, 'iterations': 1303, 'eval_metric': 'Accuracy'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 12:59:57,697] Trial 37 finished with value: 0.9566760305812473 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.08786214170075285, 'depth': 4, 'iterations': 991, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 13:00:52,093] Trial 38 finished with value: 0.947064487190248 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.0948901970011845, 'depth': 10, 'iterations': 420, 'eval_metric': 'Accuracy'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 13:01:52,184] Trial 39 finished with value: 0.957106306325613 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.08084920209057897, 'depth': 4, 'iterations': 1116, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 13:02:58,645] Trial 40 finished with value: 0.9516518528704594 and parameters: {'loss_function': 'CrossEntropy', 'learning_rate': 0.08720854548553848, 'depth': 8, 'iterations': 803, 'eval_metric': 'Accuracy'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 13:03:57,903] Trial 41 finished with value: 0.9570272756009007 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.08052215198393305, 'depth': 4, 'iterations': 1136, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 13:05:01,745] Trial 42 finished with value: 0.9571684069975172 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.08237621794474012, 'depth': 4, 'iterations': 1220, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 13:06:19,335] Trial 43 finished with value: 0.9574508364720009 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.0956128454285576, 'depth': 5, 'iterations': 1325, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 13:07:34,322] Trial 44 finished with value: 0.9575867531266129 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.09588816564178942, 'depth': 5, 'iterations': 1303, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 13:08:51,551] Trial 45 finished with value: 0.9573029306731005 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.09671036663726948, 'depth': 5, 'iterations': 1338, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 13:10:18,468] Trial 46 finished with value: 0.9563503116046463 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.09651967944312059, 'depth': 6, 'iterations': 1336, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 13:11:44,826] Trial 47 finished with value: 0.955276527172318 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.09624294012605072, 'depth': 5, 'iterations': 1328, 'eval_metric': 'Accuracy'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 13:13:14,158] Trial 48 finished with value: 0.9568260198957885 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.09885624461598232, 'depth': 6, 'iterations': 1232, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 13:14:38,233] Trial 49 finished with value: 0.9537271058836696 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.026116543269778424, 'depth': 5, 'iterations': 1374, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 13:16:19,353] Trial 50 finished with value: 0.9568616539661507 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.09074598103682459, 'depth': 6, 'iterations': 1397, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[I 2024-10-13 13:17:50,257] Trial 51 finished with value: 0.9573466368783459 and parameters: {'loss_function': 'Logloss', 'learning_rate': 0.08897707579634315, 'depth': 5, 'iterations': 1306, 'eval_metric': 'AUC'}. Best is trial 28 with value: 0.9578240596052154.\n",
            "[W 2024-10-13 13:18:31,628] Trial 52 failed with parameters: {'loss_function': 'Logloss', 'learning_rate': 0.0944116252988471, 'depth': 5, 'iterations': 1318, 'eval_metric': 'AUC'} because of the following error: KeyboardInterrupt('').\n",
            "Traceback (most recent call last):\n",
            "  File \"/opt/miniconda3/envs/kaggleEnv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"/var/folders/4z/8t5g8k3s159_f4j7xpxhn1t00000gn/T/ipykernel_64455/4200990932.py\", line 54, in objective\n",
            "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], cat_features=cat_cols)\n",
            "  File \"/opt/miniconda3/envs/kaggleEnv/lib/python3.12/site-packages/catboost/core.py\", line 5245, in fit\n",
            "    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,\n",
            "  File \"/opt/miniconda3/envs/kaggleEnv/lib/python3.12/site-packages/catboost/core.py\", line 2410, in _fit\n",
            "    self._train(\n",
            "  File \"/opt/miniconda3/envs/kaggleEnv/lib/python3.12/site-packages/catboost/core.py\", line 1790, in _train\n",
            "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
            "  File \"_catboost.pyx\", line 5017, in _catboost._CatBoost._train\n",
            "  File \"_catboost.pyx\", line 5066, in _catboost._CatBoost._train\n",
            "KeyboardInterrupt\n",
            "[W 2024-10-13 13:18:31,638] Trial 52 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[1;32m      3\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m,study_name\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgbm_loan\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/miniconda3/envs/kaggleEnv/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/miniconda3/envs/kaggleEnv/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[0;32m/opt/miniconda3/envs/kaggleEnv/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[0;32m/opt/miniconda3/envs/kaggleEnv/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[0;32m/opt/miniconda3/envs/kaggleEnv/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[0;32mIn[3], line 54\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trials)\u001b[0m\n\u001b[1;32m     52\u001b[0m y_train, y_valid \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39miloc[train_index], y\u001b[38;5;241m.\u001b[39miloc[valid_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Explicitly specify categorical features for CatBoost\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_cols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_valid)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     56\u001b[0m score \u001b[38;5;241m=\u001b[39m roc_auc_score(y_valid, y_pred)\n",
            "File \u001b[0;32m/opt/miniconda3/envs/kaggleEnv/lib/python3.12/site-packages/catboost/core.py:5245\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5243\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5245\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5246\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5247\u001b[0m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[0;32m/opt/miniconda3/envs/kaggleEnv/lib/python3.12/site-packages/catboost/core.py:2410\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2407\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2409\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2410\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2419\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
            "File \u001b[0;32m/opt/miniconda3/envs/kaggleEnv/lib/python3.12/site-packages/catboost/core.py:1790\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
            "File \u001b[0;32m_catboost.pyx:5017\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m_catboost.pyx:5066\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import optuna\n",
        "\n",
        "study = optuna.create_study(direction='maximize',study_name= 'lgbm_loan')\n",
        "study.optimize(objective, n_trials=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kXwIzjzWftXk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'loss_function': 'CrossEntropy',\n",
              " 'learning_rate': 0.08881827847947872,\n",
              " 'depth': 5,\n",
              " 'iterations': 1243,\n",
              " 'eval_metric': 'AUC'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study.best_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9578240596052154"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "study.best_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "kaggleEnv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
